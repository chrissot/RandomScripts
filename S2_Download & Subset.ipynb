{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ogr\n",
    "import gdal\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "import geopandas as gpd\n",
    "from datetime import date, timedelta\n",
    "from sentinelsat import SentinelAPI\n",
    "from shapely.geometry import Polygon\n",
    "from collections import OrderedDict\n",
    "from shapely.wkt import loads\n",
    "import shapely\n",
    "shapely.speedups.disable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_name = 'Dion'\n",
    "\n",
    "if area_name == 'Dion':\n",
    "    shp_name = 'DionSimpleBoundary.shp' #  \n",
    "    tiles = None\n",
    "if area_name == 'Hymettus':\n",
    "    shp_name = 'HymettusSimpleBoundary.shp'\n",
    "    tiles = ['T34SGG']\n",
    "if area_name == 'Samaria':\n",
    "    shp_name =  'SamariaSimpleBoundary.shp'   # SamariaSiteBoundary.shp too long wkt, not accepted for API query\n",
    "    tiles = ['T34SGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set project directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = r'C:\\Users\\csoti\\Desktop\\notebooks\\AUTH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set Project settings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {} \n",
    "project['inputs'] = os.path.join(projectdir, 'inputs')\n",
    "if not os.path.exists(project['inputs']):\n",
    "    os.mkdir(project['inputs'])\n",
    "\n",
    "# where shapefiles are stored\n",
    "project['shp'] = os.path.join(projectdir,'inputs',shp_name)                    # shapefile path\n",
    "assert os.path.exists(project['shp'])\n",
    "\n",
    "project['raw_images'] = os.path.join(projectdir, area_name, 'raw_images')      # where downloaded images are stored\n",
    "if not os.path.exists(project['raw_images']):\n",
    "    os.mkdir(project['raw_images'])\n",
    "    \n",
    "project['sub_images'] = os.path.join(projectdir, area_name, 'sub_images')      # where final cropped products are stored\n",
    "if not os.path.exists(project['sub_images']):\n",
    "    os.mkdir(project['sub_images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set Sentinel settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel={}\n",
    "sentinel['api'] = SentinelAPI('christiansot', 'belit61218', 'https://scihub.copernicus.eu/dhus') # username, password\n",
    "sentinel['platformname'] = 'Sentinel-2'                                                          # product selection for download\n",
    "sentinel['processinglevel'] = 'Level-2A'                                                         # processing level of product for download\n",
    "# output product settings\n",
    "sentinel['tiles'] = tiles                                                  # or, None\n",
    "sentinel['bands'] = ['B02_10m', 'SCL_20m', 'WVP_60m']                      # band selection as <band_resolution>\n",
    "sentinel['EPSG'] = 'EPSG:32634'                                            # reference system of final product\n",
    "sentinel['no_data'] = -9999                                                # no data value for final product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set Time settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20210219', '20210223')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set time period: \n",
    "WEEKLY = 4\n",
    "end = date.today()                      # or, end = date(2020, 11, 19) \n",
    "start = end - timedelta(days=WEEKLY)\n",
    "#\n",
    "end_date = end.strftime(\"%Y%m%d\"); start_date = start.strftime(\"%Y%m%d\")\n",
    "sentinel['date'] = (start_date,end_date)\n",
    "sentinel['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_S2(rawdir, api, area, date, platformname, processinglevel, tiles):\n",
    "    download_candidate = api.query(area=area, date=date,platformname= platformname, processinglevel = processinglevel) \n",
    "    download_products = OrderedDict()\n",
    "    downls_list = []\n",
    "    tiles = sentinel['tiles']\n",
    "    title_found_sum = 0\n",
    "\n",
    "    for key, value in download_candidate.items():\n",
    "        for k, v in value.items():\n",
    "\n",
    "            if tiles != None:\n",
    "                for tile in tiles:\n",
    "                    if k == 'title' and v.split('_')[5]== tile:\n",
    "                        prod_title = v\n",
    "                        downls_list.append(os.path.join(rawdir, prod_title + '.zip'))\n",
    "                        title_found_sum += 1\n",
    "                        download_products[key] = value\n",
    "                        for prodkey, size in value.items():\n",
    "                            if prodkey == 'size' :\n",
    "                                print(\"title: \" + prod_title + \" | \" + size)\n",
    "            if tiles == None:\n",
    "                if k == 'title':\n",
    "                    prod_title = v\n",
    "                    downls_list.append(os.path.join(rawdir, prod_title + '.zip'))\n",
    "                    title_found_sum += 1\n",
    "                    download_products[key] = value\n",
    "                elif k == 'size':\n",
    "                    print(\"title: \" + prod_title + \" | \" + v)\n",
    "\n",
    "    print(\"Total found \" + str(title_found_sum) +\n",
    "      \" title of \" + str(api.get_products_size(download_products)) + \" GB\")\n",
    "\n",
    "    rawdir = project['raw_images']\n",
    "    os.chdir(rawdir)\n",
    "    if (rawdir + \"*.zip\") not in [value for value in download_products.items()]:\n",
    "        api.download_all(download_products)\n",
    "        print(\"Finish Downloading\")\n",
    "    else:\n",
    "        print(\"Escaping download\")\n",
    "\n",
    "    return downls_list\n",
    "\n",
    "\n",
    "def un_zipFiles(downls_list):\n",
    "    \"\"\"\n",
    "    Unzip files. Requires folder path\n",
    "    \"\"\"    \n",
    "    for file in tqdm(downls_list):\n",
    "        if file.endswith('.zip'):\n",
    "            print('\\n')\n",
    "            print(\"unzip: \" + os.path.basename(file))\n",
    "            path = os.path.dirname(file)\n",
    "            zip_file = zipfile.ZipFile(file)\n",
    "            for names in zip_file.namelist():\n",
    "                zip_file.extract(names,path)\n",
    "            zip_file.close() \n",
    "            print('Finish Unzipping')\n",
    "                        \n",
    "\n",
    "def find(rootdir, endswith):\n",
    "    \"\"\"\n",
    "    Find selected data from a rootdir that end with: ex. '.tif'\n",
    "    \"\"\"    \n",
    "    finder = []\n",
    "    for root, dirs, files in os.walk(rootdir):\n",
    "        for f in files:\n",
    "            if f.endswith(endswith):\n",
    "                fullpath = os.path.join(root, f)\n",
    "                finder.append(fullpath)\n",
    "    return finder\n",
    "        \n",
    "\n",
    "def wkt_from_WGS84_shp(shp):\n",
    "    \"\"\"\n",
    "    Get wkt from WGS84 shapefile. Requires shapefile path\n",
    "    \"\"\"    \n",
    "    shp_input = ogr.Open(shp)\n",
    "    layer = shp_input.GetLayer()\n",
    "    shp_prj = layer.GetSpatialRef().ExportToProj4()\n",
    "    # check if shp in in WGS84 ref. system\n",
    "    if shp_prj == '+proj=longlat +datum=WGS84 +no_defs':\n",
    "\n",
    "        geoms = []\n",
    "        for feature in layer:\n",
    "            geom = feature.GetGeometryRef()\n",
    "            geoms.append(geom.ExportToWkt())\n",
    "\n",
    "        pol = loads(geoms[0])\n",
    "        wkt = Polygon(pol.exterior.coords).wkt\n",
    "        return wkt\n",
    "    else:\n",
    "        raise ValueError('shapefile not in WGS84 ref. system')\n",
    "                \n",
    "\n",
    "def reprj_shp(shp, EPSG):\n",
    "    \"\"\"\n",
    "    Reproject shapefile to ESPG. Requires shapefile path and EPSG as ''EPSG:32634''\n",
    "    \"\"\"  \n",
    "    outdir = os.path.dirname(shp) #  reprojects to the same folder where input shapefile is\n",
    "    input_shp = gpd.read_file(shp)\n",
    "    # change CRS \n",
    "    output_shp = input_shp.to_crs(EPSG)\n",
    "    # write shp file\n",
    "    epsg = '_' + 'epsg' + EPSG.split(':')[1]\n",
    "    reprj_shp_name = os.path.basename(shp).replace('.shp', epsg + '.shp')\n",
    "    reprj_shp_path = os.path.join(outdir,reprj_shp_name)\n",
    "    if not os.path.exists(reprj_shp_path):\n",
    "        reprj_shp = output_shp.to_file(reprj_shp_path)\n",
    "    return reprj_shp_path\n",
    "\n",
    "\n",
    "def get_coords_from_shp(shp):\n",
    "    \"\"\"\n",
    "    Get shapefile coordinates. Requires shapefile path \n",
    "    \"\"\"  \n",
    "    ds = ogr.Open(shp)\n",
    "    lyr = ds.GetLayer()\n",
    "    ft = lyr.GetFeature(0)\n",
    "    geom = ft.GetGeometryRef()\n",
    "    coords_shp = geom.GetEnvelope()\n",
    "    geom = None\n",
    "    ft = None\n",
    "    lyr = None\n",
    "    ds = None\n",
    "    return coords_shp\n",
    "\n",
    "\n",
    "def subset_tif(outdir, tif_list, shp, extent, dstNodata):\n",
    "    \"\"\"\n",
    "    Subset images to shapefile extent. \n",
    "    Requires; output path, list of images-path, shapefile path/extent, and no-data value\n",
    "    \"\"\"  \n",
    "    for file in tif_list:\n",
    "        if os.path.exists(file):\n",
    "            filename = os.path.basename(file).replace('.jp2', '_sub.tif')\n",
    "            outtif = os.path.join(outdir,filename)\n",
    "\n",
    "            if not os.path.exists(outtif):\n",
    "                \n",
    "                input_tif = gdal.Open(file)\n",
    "                options = gdal.WarpOptions(cutlineDSName=shp,outputBounds= extent, dstNodata=dstNodata)\n",
    "                outBand = gdal.Warp(srcDSOrSrcDSTab=input_tif,\n",
    "                    destNameOrDestDS=outtif,\n",
    "                    options=options)                \n",
    "                \n",
    "                input_tif = None\n",
    "\n",
    "                print('File subsetting to AOI:')\n",
    "                print(outtif)\n",
    "            \n",
    "            else:\n",
    "                print('File already exists:')\n",
    "                print(outtif)\n",
    "                \n",
    "                \n",
    "def download_subset_S2bands(sentinel_dict, project_dict):\n",
    "    \"\"\"\n",
    "    Download/subset sentinel images to shapefile.\n",
    "    Requires; sentinel settings dict, project settings dict\n",
    "    \"\"\"      \n",
    "    # assert shp in WGS84 ref. system and get wkt\n",
    "    sentinel_dict['area'] = wkt_from_WGS84_shp(project_dict['shp'])\n",
    "    \n",
    "    # download s2 files for given time range and aoi\n",
    "    downls_list = download_S2(rawdir=          project_dict['raw_images'],\n",
    "                                api=             sentinel_dict['api'], \n",
    "                                area=            sentinel_dict['area'], \n",
    "                                date=            sentinel_dict['date'], \n",
    "                                platformname=    sentinel_dict['platformname'], \n",
    "                                processinglevel= sentinel_dict['processinglevel'], \n",
    "                                tiles =          sentinel_dict['tiles'])\n",
    "    \n",
    "    un_zipFiles(downls_list)\n",
    "    \n",
    "    # reprj shp to desired EPSG and get extent\n",
    "    reprjShp = reprj_shp(project_dict['shp'], sentinel_dict['EPSG'])\n",
    "    coords_shp = get_coords_from_shp(reprjShp)\n",
    "    extent = [coords_shp[0],coords_shp[2],coords_shp[1],coords_shp[3]]\n",
    "\n",
    "    # get bands\n",
    "    bands_list = sentinel_dict['bands']\n",
    "    for band in bands_list:\n",
    "        for file in downls_list:\n",
    "            foldername = file.replace('.zip','.SAFE')\n",
    "            folderdir = os.path.join(project['raw_images'], foldername)\n",
    "            band_list = find(folderdir, band + '.jp2')\n",
    "            if len(band_list) == 0:\n",
    "                raise ValueError('Band %s does not exists in Sentinel-2 products.', band)\n",
    "\n",
    "        # Subset bands to shp extent\n",
    "            tif_aoi =  subset_tif(outdir =  project_dict['sub_images'],\n",
    "                                tif_list =  band_list,\n",
    "                                     shp =    reprjShp, \n",
    "                                  extent =    extent, \n",
    "                               dstNodata = sentinel_dict['no_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: S2B_MSIL2A_20210222T092029_N0214_R093_T34TFK_20210222T120056 | 999.29 MB\n",
      "Total found 1 title of 0.98 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|████████████████████████████████████████████████████████████████| 1.05G/1.05G [02:54<00:00, 6.02MB/s]\n",
      "MD5 checksumming: 100%|███████████████████████████████████████████████████████████| 1.05G/1.05G [00:14<00:00, 73.7MB/s]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Downloading\n",
      "\n",
      "\n",
      "unzip: S2B_MSIL2A_20210222T092029_N0214_R093_T34TFK_20210222T120056.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Unzipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File subsetting to AOI:\n",
      "C:\\Users\\csoti\\Desktop\\notebooks\\AUTH\\Dion\\sub_images\\T34TFK_20210222T092029_B02_10m_sub.tif\n",
      "File subsetting to AOI:\n",
      "C:\\Users\\csoti\\Desktop\\notebooks\\AUTH\\Dion\\sub_images\\T34TFK_20210222T092029_SCL_20m_sub.tif\n",
      "File subsetting to AOI:\n",
      "C:\\Users\\csoti\\Desktop\\notebooks\\AUTH\\Dion\\sub_images\\T34TFK_20210222T092029_WVP_60m_sub.tif\n"
     ]
    }
   ],
   "source": [
    "download_subset_S2bands(sentinel_dict= sentinel, project_dict= project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gmv] *",
   "language": "python",
   "name": "conda-env-gmv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
